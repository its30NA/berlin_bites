{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "28da06f7-d4f7-4411-96ac-3cb276cc17da",
   "metadata": {},
   "source": [
    "# Exploring data about Belrin Restaurants and the respected Reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3560bb65-896a-4096-b909-8d732d1df757",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IMPORT STATUS:\t DONE.\n"
     ]
    }
   ],
   "source": [
    "# Import libraries and packages\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import sys, os\n",
    "project_root = os.path.abspath(os.path.join(os.getcwd(), \"..\"))\n",
    "sys.path.append(project_root)\n",
    "\n",
    "# Machine Learning and Plotting\n",
    "from sklearn.cluster import KMeans\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Library to handle JSON files\n",
    "import json\n",
    "import requests \n",
    "\n",
    "# Import libraries and packages\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Machine Learning and Plotting\n",
    "from sklearn.cluster import KMeans\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Library to handle JSON files\n",
    "import json\n",
    "import requests \n",
    "\n",
    "# NOT IN THE DEPENDENCIES RN!! \n",
    "\n",
    "# Maps visualization:\n",
    "# import folium\n",
    "# Address to geographical data:\n",
    "#from geopy.geocoders import Nominatim\n",
    "\n",
    "# Web Scraping and Reading HTML files\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# Used with lists\n",
    "import itertools\n",
    "\n",
    "# To add delay between quries\n",
    "import time\n",
    "\n",
    "# To Ignore Warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "print(\"IMPORT STATUS:\\t DONE.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1b8f7aa-4124-4486-9f4e-bdacff49a041",
   "metadata": {},
   "source": [
    "## 1. Exploring berlin_reviews_2 csv dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2282eaf1-3665-43fd-befd-0e48caba6105",
   "metadata": {},
   "outputs": [],
   "source": [
    "berlin_reviews_2 = pd.read_csv('../data/raw/berlin_reviews_2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c4a6aba1-28ec-4edc-b40d-4ae6faf4ec0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>url</th>\n",
       "      <th>cuisines</th>\n",
       "      <th>reviews</th>\n",
       "      <th>star rating</th>\n",
       "      <th>page number</th>\n",
       "      <th>data offset</th>\n",
       "      <th>restaurant</th>\n",
       "      <th>dates</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1. Focaccino</td>\n",
       "      <td>https://www.tripadvisor.in/Restaurant_Review-g...</td>\n",
       "      <td>Italian, Sicilian</td>\n",
       "      <td>[\"The atmosphere is very classy yet cozy. The ...</td>\n",
       "      <td>4.5 of 5 bubbles</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>['13 November 2023', '23 September 2023', '28 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2. Cafe Couscous - Vege</td>\n",
       "      <td>https://www.tripadvisor.in/Restaurant_Review-g...</td>\n",
       "      <td>Healthy, Mediterranean</td>\n",
       "      <td>[\"The best wraps in Berlin period. I suggest g...</td>\n",
       "      <td>5.0 of 5 bubbles</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>['25 October 2023', '10 August 2023', '9 June ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3. Hackethals</td>\n",
       "      <td>https://www.tripadvisor.in/Restaurant_Review-g...</td>\n",
       "      <td>German, Bar</td>\n",
       "      <td>['I found this place on TripAdvisor and wanted...</td>\n",
       "      <td>4.5 of 5 bubbles</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>['8 November 2023', '4 November 2023', '4 Nove...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4. Restaurant Buschbeck's</td>\n",
       "      <td>https://www.tripadvisor.in/Restaurant_Review-g...</td>\n",
       "      <td>German, European</td>\n",
       "      <td>[\"As my wife is a coeliac I had to research pl...</td>\n",
       "      <td>5.0 of 5 bubbles</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>['24 October 2023', '1 October 2023', '15 Augu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5. 100 Gramm Bar</td>\n",
       "      <td>https://www.tripadvisor.in/Restaurant_Review-g...</td>\n",
       "      <td>Bar, Eastern European</td>\n",
       "      <td>['This place is amaizing! I loved the vibe, th...</td>\n",
       "      <td>5.0 of 5 bubbles</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>['23 August 2023', '23 August 2023', '21 April...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5785</th>\n",
       "      <td>6356. Bao Club</td>\n",
       "      <td>https://www.tripadvisor.in/Restaurant_Review-g...</td>\n",
       "      <td>Chinese, Asian</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>211</td>\n",
       "      <td>6330</td>\n",
       "      <td>6356</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5786</th>\n",
       "      <td>6357. Wurstkessel im KaDeWe</td>\n",
       "      <td>https://www.tripadvisor.in/Restaurant_Review-g...</td>\n",
       "      <td>French, International</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>211</td>\n",
       "      <td>6330</td>\n",
       "      <td>6357</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5787</th>\n",
       "      <td>6358. World of Champagne (Champagne Bar)</td>\n",
       "      <td>https://www.tripadvisor.in/Restaurant_Review-g...</td>\n",
       "      <td>French, Bar</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>211</td>\n",
       "      <td>6330</td>\n",
       "      <td>6358</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5788</th>\n",
       "      <td>6359. Chibo</td>\n",
       "      <td>https://www.tripadvisor.in/Restaurant_Review-g...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>211</td>\n",
       "      <td>6330</td>\n",
       "      <td>6359</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5789</th>\n",
       "      <td>6360. Steckenpferd</td>\n",
       "      <td>https://www.tripadvisor.in/Restaurant_Review-g...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>211</td>\n",
       "      <td>6330</td>\n",
       "      <td>6360</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5790 rows Ã— 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         title  \\\n",
       "0                                 1. Focaccino   \n",
       "1                      2. Cafe Couscous - Vege   \n",
       "2                                3. Hackethals   \n",
       "3                    4. Restaurant Buschbeck's   \n",
       "4                             5. 100 Gramm Bar   \n",
       "...                                        ...   \n",
       "5785                            6356. Bao Club   \n",
       "5786               6357. Wurstkessel im KaDeWe   \n",
       "5787  6358. World of Champagne (Champagne Bar)   \n",
       "5788                               6359. Chibo   \n",
       "5789                        6360. Steckenpferd   \n",
       "\n",
       "                                                    url  \\\n",
       "0     https://www.tripadvisor.in/Restaurant_Review-g...   \n",
       "1     https://www.tripadvisor.in/Restaurant_Review-g...   \n",
       "2     https://www.tripadvisor.in/Restaurant_Review-g...   \n",
       "3     https://www.tripadvisor.in/Restaurant_Review-g...   \n",
       "4     https://www.tripadvisor.in/Restaurant_Review-g...   \n",
       "...                                                 ...   \n",
       "5785  https://www.tripadvisor.in/Restaurant_Review-g...   \n",
       "5786  https://www.tripadvisor.in/Restaurant_Review-g...   \n",
       "5787  https://www.tripadvisor.in/Restaurant_Review-g...   \n",
       "5788  https://www.tripadvisor.in/Restaurant_Review-g...   \n",
       "5789  https://www.tripadvisor.in/Restaurant_Review-g...   \n",
       "\n",
       "                    cuisines  \\\n",
       "0          Italian, Sicilian   \n",
       "1     Healthy, Mediterranean   \n",
       "2                German, Bar   \n",
       "3           German, European   \n",
       "4      Bar, Eastern European   \n",
       "...                      ...   \n",
       "5785          Chinese, Asian   \n",
       "5786   French, International   \n",
       "5787             French, Bar   \n",
       "5788                     NaN   \n",
       "5789                     NaN   \n",
       "\n",
       "                                                reviews       star rating  \\\n",
       "0     [\"The atmosphere is very classy yet cozy. The ...  4.5 of 5 bubbles   \n",
       "1     [\"The best wraps in Berlin period. I suggest g...  5.0 of 5 bubbles   \n",
       "2     ['I found this place on TripAdvisor and wanted...  4.5 of 5 bubbles   \n",
       "3     [\"As my wife is a coeliac I had to research pl...  5.0 of 5 bubbles   \n",
       "4     ['This place is amaizing! I loved the vibe, th...  5.0 of 5 bubbles   \n",
       "...                                                 ...               ...   \n",
       "5785                                                NaN               NaN   \n",
       "5786                                                NaN               NaN   \n",
       "5787                                                NaN               NaN   \n",
       "5788                                                NaN               NaN   \n",
       "5789                                                NaN               NaN   \n",
       "\n",
       "      page number  data offset  restaurant  \\\n",
       "0               0            0           1   \n",
       "1               0            0           2   \n",
       "2               0            0           3   \n",
       "3               0            0           4   \n",
       "4               0            0           5   \n",
       "...           ...          ...         ...   \n",
       "5785          211         6330        6356   \n",
       "5786          211         6330        6357   \n",
       "5787          211         6330        6358   \n",
       "5788          211         6330        6359   \n",
       "5789          211         6330        6360   \n",
       "\n",
       "                                                  dates  \n",
       "0     ['13 November 2023', '23 September 2023', '28 ...  \n",
       "1     ['25 October 2023', '10 August 2023', '9 June ...  \n",
       "2     ['8 November 2023', '4 November 2023', '4 Nove...  \n",
       "3     ['24 October 2023', '1 October 2023', '15 Augu...  \n",
       "4     ['23 August 2023', '23 August 2023', '21 April...  \n",
       "...                                                 ...  \n",
       "5785                                                NaN  \n",
       "5786                                                NaN  \n",
       "5787                                                NaN  \n",
       "5788                                                NaN  \n",
       "5789                                                NaN  \n",
       "\n",
       "[5790 rows x 9 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "berlin_reviews_2    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3887145-8923-4088-b40c-18b3292ce4f7",
   "metadata": {},
   "source": [
    "### Is it useable tho?\n",
    "This Dataset has been updated 6 months ago! \n",
    "But seems like the reviews are still from late 2023 or older! \n",
    "Lets check if that's true!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b831bf28-3a27-4872-a10a-091066784219",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# convert each stringified list of date strings into actual datetime objects\n",
    "import ast\n",
    "\n",
    "# First tunring stringified lists to ACTUAL lists:\n",
    "berlin_reviews_2[\"dates\"] = berlin_reviews_2[\"dates\"].apply(\n",
    "    lambda x: ast.literal_eval(x) if isinstance(x, str) and x.startswith(\"[\") else x\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "27146b34-8c90-431e-a7a6-641ee2466b85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now getting lazy and using my preprocessing methods to turn lists of strings to list of dates\n",
    "from src.preprocessing import add_date_features\n",
    "berlin_reviews_2 = add_date_features(berlin_reviews_2, date_column=\"dates\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b41a0f12-364c-4484-ba32-b992ee0c6436",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Timestamp('2023-11-13 00:00:00'),\n",
       " Timestamp('2023-09-23 00:00:00'),\n",
       " Timestamp('2023-08-28 00:00:00'),\n",
       " Timestamp('2023-08-11 00:00:00'),\n",
       " Timestamp('2023-08-08 00:00:00'),\n",
       " Timestamp('2023-08-01 00:00:00'),\n",
       " Timestamp('2023-07-01 00:00:00'),\n",
       " Timestamp('2023-06-10 00:00:00'),\n",
       " Timestamp('2023-05-14 00:00:00'),\n",
       " Timestamp('2023-05-10 00:00:00'),\n",
       " Timestamp('2023-04-11 00:00:00'),\n",
       " Timestamp('2023-01-31 00:00:00'),\n",
       " Timestamp('2023-01-13 00:00:00'),\n",
       " Timestamp('2022-12-28 00:00:00'),\n",
       " Timestamp('2022-12-04 00:00:00'),\n",
       " Timestamp('2022-06-22 00:00:00'),\n",
       " Timestamp('2022-05-16 00:00:00'),\n",
       " Timestamp('2022-05-11 00:00:00'),\n",
       " Timestamp('2022-02-10 00:00:00'),\n",
       " Timestamp('2022-02-09 00:00:00'),\n",
       " Timestamp('2021-08-11 00:00:00'),\n",
       " Timestamp('2020-09-03 00:00:00'),\n",
       " Timestamp('2020-07-24 00:00:00'),\n",
       " Timestamp('2020-01-03 00:00:00'),\n",
       " Timestamp('2019-12-26 00:00:00'),\n",
       " Timestamp('2019-10-09 00:00:00'),\n",
       " Timestamp('2019-10-01 00:00:00'),\n",
       " Timestamp('2019-09-28 00:00:00'),\n",
       " Timestamp('2019-06-14 00:00:00'),\n",
       " Timestamp('2019-05-03 00:00:00'),\n",
       " Timestamp('2019-04-15 00:00:00'),\n",
       " Timestamp('2019-04-15 00:00:00'),\n",
       " Timestamp('2019-03-28 00:00:00'),\n",
       " Timestamp('2019-03-18 00:00:00'),\n",
       " Timestamp('2019-03-13 00:00:00'),\n",
       " Timestamp('2018-12-05 00:00:00'),\n",
       " Timestamp('2018-11-22 00:00:00'),\n",
       " Timestamp('2018-11-21 00:00:00'),\n",
       " Timestamp('2018-10-27 00:00:00'),\n",
       " Timestamp('2018-10-26 00:00:00'),\n",
       " Timestamp('2018-10-23 00:00:00'),\n",
       " Timestamp('2018-10-23 00:00:00'),\n",
       " Timestamp('2018-10-23 00:00:00'),\n",
       " Timestamp('2018-10-05 00:00:00'),\n",
       " Timestamp('2018-09-24 00:00:00'),\n",
       " Timestamp('2018-09-05 00:00:00'),\n",
       " Timestamp('2018-09-04 00:00:00'),\n",
       " Timestamp('2018-09-04 00:00:00'),\n",
       " Timestamp('2018-08-21 00:00:00'),\n",
       " Timestamp('2018-08-13 00:00:00'),\n",
       " Timestamp('2018-07-04 00:00:00'),\n",
       " Timestamp('2018-06-12 00:00:00'),\n",
       " Timestamp('2018-06-04 00:00:00'),\n",
       " Timestamp('2018-05-19 00:00:00'),\n",
       " Timestamp('2018-05-19 00:00:00'),\n",
       " Timestamp('2018-05-18 00:00:00'),\n",
       " Timestamp('2018-05-09 00:00:00'),\n",
       " Timestamp('2018-05-03 00:00:00'),\n",
       " Timestamp('2018-05-02 00:00:00'),\n",
       " Timestamp('2018-05-02 00:00:00'),\n",
       " Timestamp('2018-05-01 00:00:00'),\n",
       " Timestamp('2018-05-01 00:00:00'),\n",
       " Timestamp('2018-04-30 00:00:00'),\n",
       " Timestamp('2018-03-15 00:00:00'),\n",
       " Timestamp('2018-03-11 00:00:00'),\n",
       " Timestamp('2018-03-03 00:00:00'),\n",
       " Timestamp('2018-01-22 00:00:00'),\n",
       " Timestamp('2018-01-22 00:00:00'),\n",
       " Timestamp('2018-01-15 00:00:00'),\n",
       " Timestamp('2017-12-19 00:00:00'),\n",
       " Timestamp('2017-12-14 00:00:00'),\n",
       " Timestamp('2017-12-06 00:00:00'),\n",
       " Timestamp('2017-11-19 00:00:00'),\n",
       " Timestamp('2017-11-17 00:00:00'),\n",
       " Timestamp('2017-11-12 00:00:00'),\n",
       " Timestamp('2017-10-22 00:00:00'),\n",
       " Timestamp('2017-10-21 00:00:00'),\n",
       " Timestamp('2017-10-06 00:00:00'),\n",
       " Timestamp('2017-09-27 00:00:00'),\n",
       " Timestamp('2017-08-28 00:00:00'),\n",
       " Timestamp('2017-08-23 00:00:00'),\n",
       " Timestamp('2017-08-13 00:00:00'),\n",
       " Timestamp('2017-06-18 00:00:00'),\n",
       " Timestamp('2017-06-07 00:00:00'),\n",
       " Timestamp('2017-05-18 00:00:00'),\n",
       " Timestamp('2017-05-08 00:00:00'),\n",
       " Timestamp('2017-04-23 00:00:00'),\n",
       " Timestamp('2017-04-23 00:00:00'),\n",
       " Timestamp('2017-04-15 00:00:00'),\n",
       " Timestamp('2017-04-14 00:00:00'),\n",
       " Timestamp('2017-04-12 00:00:00'),\n",
       " Timestamp('2017-04-11 00:00:00'),\n",
       " Timestamp('2017-04-09 00:00:00'),\n",
       " Timestamp('2017-04-03 00:00:00'),\n",
       " Timestamp('2017-03-29 00:00:00'),\n",
       " Timestamp('2017-03-23 00:00:00'),\n",
       " Timestamp('2017-03-08 00:00:00'),\n",
       " Timestamp('2017-02-21 00:00:00'),\n",
       " Timestamp('2017-02-19 00:00:00'),\n",
       " Timestamp('2017-02-15 00:00:00'),\n",
       " Timestamp('2017-01-28 00:00:00'),\n",
       " Timestamp('2017-01-25 00:00:00'),\n",
       " Timestamp('2017-01-22 00:00:00'),\n",
       " Timestamp('2017-01-19 00:00:00'),\n",
       " Timestamp('2017-01-09 00:00:00'),\n",
       " Timestamp('2016-12-20 00:00:00'),\n",
       " Timestamp('2016-12-13 00:00:00'),\n",
       " Timestamp('2016-12-11 00:00:00'),\n",
       " Timestamp('2016-12-05 00:00:00'),\n",
       " Timestamp('2016-12-01 00:00:00'),\n",
       " Timestamp('2016-11-22 00:00:00'),\n",
       " Timestamp('2016-11-18 00:00:00'),\n",
       " Timestamp('2016-11-16 00:00:00'),\n",
       " Timestamp('2016-11-12 00:00:00'),\n",
       " Timestamp('2016-11-02 00:00:00'),\n",
       " Timestamp('2016-11-01 00:00:00'),\n",
       " Timestamp('2016-10-29 00:00:00'),\n",
       " Timestamp('2016-10-27 00:00:00'),\n",
       " Timestamp('2016-10-23 00:00:00'),\n",
       " Timestamp('2016-10-22 00:00:00'),\n",
       " Timestamp('2016-10-20 00:00:00'),\n",
       " Timestamp('2016-10-07 00:00:00'),\n",
       " Timestamp('2016-09-29 00:00:00'),\n",
       " Timestamp('2016-09-28 00:00:00'),\n",
       " Timestamp('2016-09-22 00:00:00'),\n",
       " Timestamp('2016-09-13 00:00:00'),\n",
       " Timestamp('2016-08-11 00:00:00'),\n",
       " Timestamp('2016-07-29 00:00:00'),\n",
       " Timestamp('2016-07-28 00:00:00'),\n",
       " Timestamp('2016-07-25 00:00:00'),\n",
       " Timestamp('2016-07-25 00:00:00'),\n",
       " Timestamp('2016-07-22 00:00:00'),\n",
       " Timestamp('2016-07-21 00:00:00'),\n",
       " Timestamp('2016-07-21 00:00:00'),\n",
       " Timestamp('2016-07-20 00:00:00'),\n",
       " Timestamp('2016-07-20 00:00:00'),\n",
       " Timestamp('2016-07-18 00:00:00'),\n",
       " Timestamp('2016-07-15 00:00:00'),\n",
       " Timestamp('2016-07-14 00:00:00'),\n",
       " Timestamp('2016-07-13 00:00:00'),\n",
       " Timestamp('2016-07-11 00:00:00'),\n",
       " Timestamp('2016-07-02 00:00:00'),\n",
       " Timestamp('2016-06-28 00:00:00'),\n",
       " Timestamp('2016-06-26 00:00:00'),\n",
       " Timestamp('2016-06-21 00:00:00'),\n",
       " Timestamp('2016-06-15 00:00:00'),\n",
       " Timestamp('2016-05-29 00:00:00'),\n",
       " Timestamp('2016-05-29 00:00:00'),\n",
       " Timestamp('2016-05-25 00:00:00'),\n",
       " Timestamp('2016-05-24 00:00:00'),\n",
       " Timestamp('2016-05-23 00:00:00'),\n",
       " Timestamp('2016-05-22 00:00:00'),\n",
       " Timestamp('2016-05-21 00:00:00'),\n",
       " Timestamp('2016-05-18 00:00:00'),\n",
       " Timestamp('2016-05-18 00:00:00'),\n",
       " Timestamp('2016-05-17 00:00:00'),\n",
       " Timestamp('2016-04-29 00:00:00'),\n",
       " Timestamp('2016-04-27 00:00:00'),\n",
       " Timestamp('2016-04-26 00:00:00'),\n",
       " Timestamp('2016-03-30 00:00:00'),\n",
       " Timestamp('2016-03-27 00:00:00'),\n",
       " Timestamp('2016-03-06 00:00:00'),\n",
       " Timestamp('2016-03-05 00:00:00'),\n",
       " Timestamp('2016-02-17 00:00:00'),\n",
       " Timestamp('2016-02-09 00:00:00'),\n",
       " Timestamp('2015-11-07 00:00:00'),\n",
       " Timestamp('2015-10-30 00:00:00'),\n",
       " Timestamp('2015-10-29 00:00:00'),\n",
       " Timestamp('2015-10-19 00:00:00'),\n",
       " Timestamp('2015-10-13 00:00:00'),\n",
       " Timestamp('2015-10-13 00:00:00'),\n",
       " Timestamp('2015-10-10 00:00:00'),\n",
       " Timestamp('2015-10-08 00:00:00'),\n",
       " Timestamp('2015-09-30 00:00:00'),\n",
       " Timestamp('2015-09-29 00:00:00'),\n",
       " Timestamp('2015-09-22 00:00:00'),\n",
       " Timestamp('2015-09-20 00:00:00'),\n",
       " Timestamp('2015-09-16 00:00:00'),\n",
       " Timestamp('2015-09-13 00:00:00'),\n",
       " Timestamp('2015-09-12 00:00:00'),\n",
       " Timestamp('2015-09-11 00:00:00'),\n",
       " Timestamp('2015-09-06 00:00:00'),\n",
       " Timestamp('2015-08-31 00:00:00'),\n",
       " Timestamp('2015-08-24 00:00:00'),\n",
       " Timestamp('2015-08-22 00:00:00'),\n",
       " Timestamp('2015-08-20 00:00:00'),\n",
       " Timestamp('2015-08-19 00:00:00'),\n",
       " Timestamp('2015-08-15 00:00:00'),\n",
       " Timestamp('2015-08-13 00:00:00'),\n",
       " Timestamp('2015-07-19 00:00:00'),\n",
       " Timestamp('2015-07-14 00:00:00'),\n",
       " Timestamp('2015-07-04 00:00:00'),\n",
       " Timestamp('2015-06-15 00:00:00'),\n",
       " Timestamp('2015-06-10 00:00:00'),\n",
       " Timestamp('2015-05-25 00:00:00'),\n",
       " Timestamp('2015-04-24 00:00:00'),\n",
       " Timestamp('2015-03-27 00:00:00'),\n",
       " Timestamp('2015-03-21 00:00:00'),\n",
       " Timestamp('2015-03-05 00:00:00'),\n",
       " Timestamp('2015-02-28 00:00:00'),\n",
       " Timestamp('2015-02-25 00:00:00'),\n",
       " Timestamp('2015-02-22 00:00:00'),\n",
       " Timestamp('2015-02-11 00:00:00'),\n",
       " Timestamp('2015-01-30 00:00:00'),\n",
       " Timestamp('2014-12-05 00:00:00'),\n",
       " Timestamp('2014-09-29 00:00:00'),\n",
       " Timestamp('2014-09-26 00:00:00'),\n",
       " Timestamp('2014-09-10 00:00:00'),\n",
       " Timestamp('2014-06-23 00:00:00'),\n",
       " Timestamp('2013-12-12 00:00:00'),\n",
       " Timestamp('2013-10-11 00:00:00'),\n",
       " Timestamp('2013-07-30 00:00:00'),\n",
       " Timestamp('2012-07-12 00:00:00'),\n",
       " Timestamp('2012-05-28 00:00:00'),\n",
       " Timestamp('2012-02-13 00:00:00'),\n",
       " Timestamp('2012-01-14 00:00:00'),\n",
       " Timestamp('2011-08-19 00:00:00'),\n",
       " Timestamp('2023-11-13 00:00:00'),\n",
       " Timestamp('2023-09-23 00:00:00'),\n",
       " Timestamp('2023-08-28 00:00:00'),\n",
       " Timestamp('2023-08-11 00:00:00'),\n",
       " Timestamp('2023-08-08 00:00:00'),\n",
       " Timestamp('2023-08-01 00:00:00'),\n",
       " Timestamp('2023-07-01 00:00:00'),\n",
       " Timestamp('2023-06-10 00:00:00'),\n",
       " Timestamp('2023-05-14 00:00:00'),\n",
       " Timestamp('2023-05-10 00:00:00'),\n",
       " Timestamp('2023-04-11 00:00:00'),\n",
       " Timestamp('2023-01-31 00:00:00'),\n",
       " Timestamp('2023-01-13 00:00:00'),\n",
       " Timestamp('2022-12-28 00:00:00'),\n",
       " Timestamp('2022-12-04 00:00:00')]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "berlin_reviews_2[\"dates_parsed\"].iloc[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56ca35cd-1211-437a-9c1f-3733edf5e14c",
   "metadata": {},
   "source": [
    "Look above, weird behavior is noticed.. the first dates match the last dates... looks like some dates repeated... why?!\n",
    "Let's check some other rows!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cad1dded-dff7-4e5f-88cc-12b27352d5b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Timestamp('2023-10-25 00:00:00'),\n",
       " Timestamp('2023-08-10 00:00:00'),\n",
       " Timestamp('2023-06-09 00:00:00'),\n",
       " Timestamp('2023-04-18 00:00:00'),\n",
       " Timestamp('2023-03-12 00:00:00'),\n",
       " Timestamp('2023-02-10 00:00:00'),\n",
       " Timestamp('2023-02-07 00:00:00'),\n",
       " Timestamp('2023-01-21 00:00:00'),\n",
       " Timestamp('2023-01-06 00:00:00'),\n",
       " Timestamp('2022-12-10 00:00:00'),\n",
       " Timestamp('2022-09-14 00:00:00'),\n",
       " Timestamp('2022-06-16 00:00:00'),\n",
       " Timestamp('2022-06-03 00:00:00'),\n",
       " Timestamp('2022-03-04 00:00:00'),\n",
       " Timestamp('2021-06-24 00:00:00'),\n",
       " Timestamp('2021-04-17 00:00:00'),\n",
       " Timestamp('2020-07-31 00:00:00'),\n",
       " Timestamp('2019-12-21 00:00:00'),\n",
       " Timestamp('2019-08-21 00:00:00'),\n",
       " Timestamp('2019-08-20 00:00:00'),\n",
       " Timestamp('2019-08-14 00:00:00'),\n",
       " Timestamp('2019-07-04 00:00:00'),\n",
       " Timestamp('2019-06-14 00:00:00'),\n",
       " Timestamp('2019-06-13 00:00:00'),\n",
       " Timestamp('2019-06-07 00:00:00'),\n",
       " Timestamp('2019-06-04 00:00:00'),\n",
       " Timestamp('2019-06-01 00:00:00'),\n",
       " Timestamp('2019-05-24 00:00:00'),\n",
       " Timestamp('2019-05-11 00:00:00'),\n",
       " Timestamp('2019-01-31 00:00:00'),\n",
       " Timestamp('2019-01-08 00:00:00'),\n",
       " Timestamp('2018-12-05 00:00:00'),\n",
       " Timestamp('2018-11-29 00:00:00'),\n",
       " Timestamp('2018-11-16 00:00:00'),\n",
       " Timestamp('2018-11-09 00:00:00'),\n",
       " Timestamp('2018-11-09 00:00:00'),\n",
       " Timestamp('2018-10-24 00:00:00'),\n",
       " Timestamp('2018-10-24 00:00:00'),\n",
       " Timestamp('2018-10-18 00:00:00'),\n",
       " Timestamp('2018-10-15 00:00:00'),\n",
       " Timestamp('2018-08-25 00:00:00'),\n",
       " Timestamp('2018-07-25 00:00:00'),\n",
       " Timestamp('2018-04-07 00:00:00'),\n",
       " Timestamp('2017-07-15 00:00:00'),\n",
       " Timestamp('2016-09-05 00:00:00'),\n",
       " Timestamp('2016-05-29 00:00:00'),\n",
       " Timestamp('2016-03-06 00:00:00'),\n",
       " Timestamp('2023-10-25 00:00:00'),\n",
       " Timestamp('2023-08-10 00:00:00'),\n",
       " Timestamp('2023-06-09 00:00:00'),\n",
       " Timestamp('2023-04-18 00:00:00'),\n",
       " Timestamp('2023-03-12 00:00:00'),\n",
       " Timestamp('2023-02-10 00:00:00'),\n",
       " Timestamp('2023-02-07 00:00:00'),\n",
       " Timestamp('2023-01-21 00:00:00'),\n",
       " Timestamp('2023-01-06 00:00:00'),\n",
       " Timestamp('2022-12-10 00:00:00'),\n",
       " Timestamp('2022-09-14 00:00:00'),\n",
       " Timestamp('2022-06-16 00:00:00'),\n",
       " Timestamp('2022-06-03 00:00:00'),\n",
       " Timestamp('2022-03-04 00:00:00'),\n",
       " Timestamp('2021-06-24 00:00:00')]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "berlin_reviews_2[\"dates_parsed\"].iloc[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32107f77-fc28-456b-bb01-a3d691934524",
   "metadata": {},
   "source": [
    "AGAIN!! We have EXACTLY 15 first dates matching the 15 last dates... that's a problem! Have i caused it? or the dataset has been like that since the beginning??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3b26b528-168f-4047-adb6-e579e517646f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "index nr = 3532\n",
      "[Timestamp('2018-08-08 00:00:00'), Timestamp('2015-09-13 00:00:00'), Timestamp('2015-08-04 00:00:00'), Timestamp('2015-06-25 00:00:00'), Timestamp('2015-04-20 00:00:00'), Timestamp('2012-09-23 00:00:00'), Timestamp('2018-08-08 00:00:00'), Timestamp('2015-09-13 00:00:00'), Timestamp('2015-08-04 00:00:00'), Timestamp('2015-06-25 00:00:00'), Timestamp('2015-04-20 00:00:00'), Timestamp('2012-09-23 00:00:00')]\n"
     ]
    }
   ],
   "source": [
    "# i check some random rows, to see if the exact 15 dates match, then i check the review! if the reviews are the same... then we need cleaning!!\n",
    "random_row = np.random.randint(0, 5000)\n",
    "print('index nr =', random_row)\n",
    "print(berlin_reviews_2[\"dates_parsed\"].iloc[random_row])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "095c6e05-92a0-4a8f-b85e-fe869e6662f6",
   "metadata": {},
   "source": [
    "Some useful insights from the above algorythm:\n",
    "\n",
    "index nr = 4205\n",
    "\n",
    "[Timestamp('2023-09-27 00:00:00'), Timestamp('2023-09-27 00:00:00')]\n",
    "\n",
    "index nr = 2227\n",
    "\n",
    "['3 June 2023', '30 December 2019', '15 August 2019', '1 June 2019', '6 May 2019', '3 June 2023', '30 December 2019', '15 August 2019', '1 June 2019', '6 May 2019']\n",
    "\n",
    "index nr = 4675\n",
    "\n",
    "['28 May 2023', '28 May 2023']\n",
    "\n",
    "\n",
    "So now we have another challenge, when the nr of reviews and therefore the date of reviews are less than 15 in tottal!! \n",
    "### ACTION: Cleaning later needed!\n",
    "### Cleaning 1: Done [ ]  or  Due [ ]\n",
    "DO THIS: when less than 15 review dates, clean the last half! EZ PZ!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3cdd98f7-8e61-47ac-9c4b-d40dfba46a98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>earliest_date</th>\n",
       "      <th>latest_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2011-08-19</td>\n",
       "      <td>2023-11-13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2016-03-06</td>\n",
       "      <td>2023-10-25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2008-01-19</td>\n",
       "      <td>2023-11-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2017-05-08</td>\n",
       "      <td>2023-10-24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019-05-07</td>\n",
       "      <td>2023-08-23</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  earliest_date latest_date\n",
       "0    2011-08-19  2023-11-13\n",
       "1    2016-03-06  2023-10-25\n",
       "2    2008-01-19  2023-11-08\n",
       "3    2017-05-08  2023-10-24\n",
       "4    2019-05-07  2023-08-23"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now back to extracting earliest and latest review to see if the dataset is up to date as kaggle shows:\n",
    "berlin_reviews_2[[\"earliest_date\", \"latest_date\"]].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "89d18179-4244-40a5-b154-f1a3b5f0f959",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2007-11-01 00:00:00\n",
      "2023-11-20 00:00:00\n"
     ]
    }
   ],
   "source": [
    "print(berlin_reviews_2[\"earliest_date\"].min())\n",
    "print(berlin_reviews_2[\"latest_date\"].max())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53c87d53-0f20-43b3-88e1-3cee4d1cfb59",
   "metadata": {},
   "source": [
    "### Summary of Dataset berlin_reviews_2:\n",
    "**1st Summary:**\n",
    "The author has updated this dataset 6 months ago on Kaggle, but still the last review goes back to 2023.\n",
    "In all honesty, just exploring random data on this data set, i could tell the latest reviews are mostly from 2023 and then 2022 and so on. so it def is not too old to maneuver with! But a more updated dataset is appreciated. Off the next dataset now!\n",
    "\n",
    "Newest Review:2023-11-20\n",
    "\n",
    "Oldest Review: 2007-11-01"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "757b56a7-ead4-43df-8b06-3e5ef59cd309",
   "metadata": {},
   "source": [
    "## 2. Foursquare API for berlin venues:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "84381a8d-402a-4c2b-8069-4e44adaefabd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# @hidden_cell\n",
    "\n",
    "CLIENT_ID = 'HIE5ISYEZQEQPNSVGQGRWCJMXA43OC3MBRHICDU01GF1P0EA' # your Foursquare ID\n",
    "CLIENT_SECRET = 'DK3E0ME2RXUUXAOX54VSSULBVYBUJWUD4BRVAQIJMV2ZIG54' # your Foursquare Secret\n",
    "VERSION = '20190701' # Foursquare API version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "339e576e-1495-49ed-b2fd-55628570fe88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Returns a DataFrame with Venue details\n",
    "def getNearbyVenues(names, latitudes, longitudes, radius, LIMIT):\n",
    "    \n",
    "    venues_list=[]\n",
    "    for name, lat, lng in zip(names, latitudes, longitudes):\n",
    "        # create the API request URL\n",
    "        url = 'https://api.foursquare.com/v2/venues/explore?&client_id={}&client_secret={}&v={}&ll={},{}&radius={}&limit={}'.format(\n",
    "            CLIENT_ID, \n",
    "            CLIENT_SECRET, \n",
    "            VERSION, \n",
    "            lat, \n",
    "            lng, \n",
    "            radius, \n",
    "            LIMIT)\n",
    "            \n",
    "        # make the GET request\n",
    "        results = requests.get(url).json()[\"response\"]['groups'][0]['items']\n",
    "        # return only relevant information for each nearby venue\n",
    "        venues_list.append([(\n",
    "            name, \n",
    "            lat, \n",
    "            lng, \n",
    "            v['venue']['name'], \n",
    "            v['venue']['location']['lat'], \n",
    "            v['venue']['location']['lng'],  \n",
    "            v['venue']['categories'][0]['name']) for v in results])\n",
    "\n",
    "    nearby_venues = pd.DataFrame([item for venue_list in venues_list for item in venue_list])\n",
    "    nearby_venues.columns = ['Neighbourhood', \n",
    "                  'Neighbourhood Latitude', \n",
    "                  'Neighbourhood Longitude', \n",
    "                  'Venue', \n",
    "                  'Venue Latitude', \n",
    "                  'Venue Longitude', \n",
    "                  'Venue Category']\n",
    "    \n",
    "    return(nearby_venues)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3a7a4998-3c02-402c-ac0b-6735a3af6e87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Returns a DataFrame with top venues based on a threshold\n",
    "def return_top_venues(row, maximum_venues):\n",
    "    \n",
    "    # Select all except neighbourhood column\n",
    "    row_categories = row.iloc[1:]\n",
    "    row_categories_sorted = row_categories.sort_values(ascending=False)\n",
    "    \n",
    "    return row_categories_sorted.index.values[0: maximum_venues]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "27d5a820-cd4b-4cfa-bf41-4cb713c957de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error fetching data, could be caused by exceeding Foursquare maximum calls/ day.\n",
      "Cannot view data: Berlin_venues DataFrame was not successfully created.\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "# Try to fetch Berlin Venues data\n",
    "try:\n",
    "    Berlin_venues = getNearbyVenues(Berlin_neighbourhoods['Neighbourhood'],\n",
    "                                        Berlin_neighbourhoods['Latitude'],\n",
    "                                        Berlin_neighbourhoods['Longitude'],\n",
    "                                        radius=2000,\n",
    "                                        LIMIT=100)\n",
    "except:\n",
    "    print('Error fetching data, could be caused by exceeding Forsquare maximum calls/ day.')\n",
    "\n",
    "# View the DataFrame\n",
    "Berlin_venues.head()\n",
    "'''\n",
    "# 1. Initialize the variable outside the try block\n",
    "Berlin_venues = None\n",
    "\n",
    "# 2. Try to fetch Berlin Venues data\n",
    "try:\n",
    "    Berlin_venues = getNearbyVenues(Berlin_neighbourhoods['Neighbourhood'],\n",
    "                                    Berlin_neighbourhoods['Latitude'],\n",
    "                                    Berlin_neighbourhoods['Longitude'],\n",
    "                                    radius=2000,\n",
    "                                    LIMIT=100)\n",
    "except Exception as e: # Catch the specific exception for better debugging\n",
    "    print('Error fetching data, could be caused by exceeding Foursquare maximum calls/ day.')\n",
    "    # print(f\"Details: {e}\") # Uncomment to see the actual error details\n",
    "\n",
    "# 3. View the DataFrame ONLY IF it was successfully created\n",
    "if Berlin_venues is not None:\n",
    "    Berlin_venues.head()\n",
    "else:\n",
    "    print(\"Cannot view data: Berlin_venues DataFrame was not successfully created.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4c6e881b-f643-4425-a204-12d8dd7851f6",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Berlin_neighbourhoods' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m Berlin_venues \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# 2. Slice the DataFrame to use only the first 5 neighborhoods\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m sample_neighbourhoods \u001b[38;5;241m=\u001b[39m \u001b[43mBerlin_neighbourhoods\u001b[49m\u001b[38;5;241m.\u001b[39mhead(\u001b[38;5;241m5\u001b[39m)\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mâœ… Attempting to fetch venues for the first \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(sample_neighbourhoods)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m neighborhoods...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# 3. Try to fetch Berlin Venues data using the smaller sample\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'Berlin_neighbourhoods' is not defined"
     ]
    }
   ],
   "source": [
    "# 1. Initialize the variable outside the try block\n",
    "Berlin_venues = None\n",
    "\n",
    "# 2. Slice the DataFrame to use only the first 5 neighborhoods\n",
    "sample_neighbourhoods = Berlin_neighbourhoods.head(5)\n",
    "\n",
    "print(f\"âœ… Attempting to fetch venues for the first {len(sample_neighbourhoods)} neighborhoods...\")\n",
    "\n",
    "# 3. Try to fetch Berlin Venues data using the smaller sample\n",
    "try:\n",
    "    Berlin_venues = getNearbyVenues(sample_neighbourhoods['Neighbourhood'],\n",
    "                                    sample_neighbourhoods['Latitude'],\n",
    "                                    sample_neighbourhoods['Longitude'],\n",
    "                                    radius=2000,\n",
    "                                    LIMIT=100)\n",
    "except Exception as e:\n",
    "    print('âŒ Error fetching data, could be caused by exceeding Foursquare maximum calls/ day or an issue with the API keys.')\n",
    "    # print(f\"Details: {e}\") # Uncomment to see the actual error details\n",
    "\n",
    "# 4. View the DataFrame ONLY IF it was successfully created\n",
    "if Berlin_venues is not None:\n",
    "    print(\"\\nðŸŽ‰ Success! Displaying the first 5 rows of the fetched data:\")\n",
    "    Berlin_venues.head()\n",
    "else:\n",
    "    print(\"\\nâš ï¸ Cannot view data: Berlin_venues DataFrame was not successfully created.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e9b9a149-5c3e-4e81-9176-305652e5568a",
   "metadata": {},
   "outputs": [
    {
     "ename": "FeatureNotFound",
     "evalue": "Couldn't find a tree builder with the features you requested: lxml. Do you need to install a parser library?",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFeatureNotFound\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Get HTML file of Berlin Neighbourhoods\u001b[39;00m\n\u001b[1;32m      2\u001b[0m Berlin_neighbourhoods_html \u001b[38;5;241m=\u001b[39m requests\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhttps://en.wikipedia.org/wiki/Boroughs_and_neighborhoods_of_Berlin\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mtext\n\u001b[0;32m----> 3\u001b[0m page \u001b[38;5;241m=\u001b[39m \u001b[43mBeautifulSoup\u001b[49m\u001b[43m(\u001b[49m\u001b[43mBerlin_neighbourhoods_html\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlxml\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# Check Webpage Title\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m1. Webpage Title: \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m----------------------\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(page\u001b[38;5;241m.\u001b[39mtitle\u001b[38;5;241m.\u001b[39mtext))\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/berlin_bites/lib/python3.10/site-packages/bs4/__init__.py:366\u001b[0m, in \u001b[0;36mBeautifulSoup.__init__\u001b[0;34m(self, markup, features, builder, parse_only, from_encoding, exclude_encodings, element_classes, **kwargs)\u001b[0m\n\u001b[1;32m    364\u001b[0m     possible_builder_class \u001b[38;5;241m=\u001b[39m builder_registry\u001b[38;5;241m.\u001b[39mlookup(\u001b[38;5;241m*\u001b[39mfeatures)\n\u001b[1;32m    365\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m possible_builder_class \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 366\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m FeatureNotFound(\n\u001b[1;32m    367\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCouldn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt find a tree builder with the features you \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    368\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrequested: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m. Do you need to install a parser library?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    369\u001b[0m             \u001b[38;5;241m%\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(features)\n\u001b[1;32m    370\u001b[0m         )\n\u001b[1;32m    371\u001b[0m     builder_class \u001b[38;5;241m=\u001b[39m possible_builder_class\n\u001b[1;32m    373\u001b[0m \u001b[38;5;66;03m# At this point either we have a TreeBuilder instance in\u001b[39;00m\n\u001b[1;32m    374\u001b[0m \u001b[38;5;66;03m# builder, or we have a builder_class that we can instantiate\u001b[39;00m\n\u001b[1;32m    375\u001b[0m \u001b[38;5;66;03m# with the remaining **kwargs.\u001b[39;00m\n",
      "\u001b[0;31mFeatureNotFound\u001b[0m: Couldn't find a tree builder with the features you requested: lxml. Do you need to install a parser library?"
     ]
    }
   ],
   "source": [
    "# Get HTML file of Berlin Neighbourhoods\n",
    "Berlin_neighbourhoods_html = requests.get('https://en.wikipedia.org/wiki/Boroughs_and_neighborhoods_of_Berlin').text\n",
    "page = BeautifulSoup(Berlin_neighbourhoods_html, 'lxml')\n",
    "\n",
    "# Check Webpage Title\n",
    "print('1. Webpage Title: \\n----------------------\\n{} \\n \\n'.format(page.title.text))\n",
    "\n",
    "# Find the first table in the webpage\n",
    "table = page.find('table')\n",
    "\n",
    "# Create a DataFrame for Boroughs in Berlin\n",
    "Berlin_boroughs = pd.DataFrame()\n",
    "\n",
    "# Assign the retrived table to a list\n",
    "data_list = pd.read_html(str(table))\n",
    "\n",
    "# Copy retrived data to the Berlin_boroughs DataFrame\n",
    "Berlin_boroughs = data_list[0]\n",
    "\n",
    "# Rename Columns and drop the Map column\n",
    "Berlin_boroughs.drop(['Map'], axis =1, inplace=True)\n",
    "Berlin_boroughs.columns = ['Boroughs', 'Population', 'Area', 'Density']\n",
    "\n",
    "print('2. DataFrame Shape:\\n----------------------\\n', Berlin_boroughs.shape,'\\n \\n')\n",
    "Berlin_boroughs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "686f05b3-a8cb-4046-9ccb-5bbda824ba6c",
   "metadata": {},
   "source": [
    "### **For NOW** i hold it with this FSQ data source! \n",
    "### It is more useful for geografical insights than reviews!\n",
    "But i have found some other veryy verryyy intersting data sources for super advanced data insights.\n",
    "\n",
    "These are as followed:\n",
    "\n",
    "https://kepler.gl/\n",
    "\n",
    "https://deck.gl/\n",
    "\n",
    "https://opensource.foursquare.com/os-places/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "503c8327-25dd-4ab5-8e57-aa66c840967b",
   "metadata": {},
   "source": [
    "## 3. yelp: https://www.youtube.com/watch?v=mn6aj3JitVo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "79019ce9-6f8e-4188-81d4-4dabe1847a92",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_yelp_reviews(api_key, location='Berlin', term='restaurant', limit=50):\n",
    "    headers = {'Authorization': f'Bearer {api_key}'}\n",
    "    url = 'https://api.yelp.com/v3/businesses/search'\n",
    "    params = {'location': location, 'term': term, 'limit': limit}\n",
    "    response = requests.get(url, headers=headers, params=params).json()\n",
    "    \n",
    "    reviews_list = []\n",
    "    for business in response['businesses']:\n",
    "        reviews_list.append({\n",
    "            'name': business['name'],\n",
    "            'rating': business['rating'],\n",
    "            'review_count': business['review_count'],\n",
    "            'category': business['categories'][0]['title']\n",
    "        })\n",
    "    return pd.DataFrame(reviews_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31a47bb3-a871-41d6-b669-d146c2e78960",
   "metadata": {},
   "source": [
    "ok so yelp only gives me 3 reviews per place... that's... not ideal for this project. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "8570aac6-787b-43e9-9097-cf180899298e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from datetime import datetime\n",
    "from typing import List, Dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "13256c12-b89e-4656-8cfd-639f4a9b9dc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "HEADERS = {\n",
    "    \"User-Agent\":\n",
    "        \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) \"\n",
    "        \"AppleWebKit/537.36 (KHTML, like Gecko) \"\n",
    "        \"Chrome/124.0.0.0 Safari/537.36 \"\n",
    "        \"Edg/124.0.2478.51\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "572a3f4f-2db1-45e9-8fb1-eee93769e433",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_yelp_berlin(term=\"restaurants\", pages=3) -> List[str]:\n",
    "    \"\"\"\n",
    "    Scrapes Yelp search results pages for restaurants in Berlin.\n",
    "    Returns list of restaurant page URLs.\n",
    "    \"\"\"\n",
    "    base_url = \"https://www.yelp.com/search\"\n",
    "    urls = []\n",
    "\n",
    "    for p in range(pages):\n",
    "        print(f\"[INFO] Fetching search page {p+1}/{pages}...\")\n",
    "        params = {\n",
    "            \"find_desc\": term,\n",
    "            \"find_loc\": \"Berlin, Germany\",\n",
    "            \"start\": p * 10\n",
    "        }\n",
    "\n",
    "        res = requests.get(base_url, headers=HEADERS, params=params)\n",
    "        soup = BeautifulSoup(res.text, \"html.parser\")\n",
    "\n",
    "        # Yelp business links look like /biz/something\n",
    "        for link in soup.select(\"a.css-1k2tj2c\"):\n",
    "            href = link.get(\"href\", \"\")\n",
    "            if href.startswith(\"/biz/\") and \"?\" not in href:\n",
    "                full_url = \"https://www.yelp.com\" + href\n",
    "                urls.append(full_url)\n",
    "\n",
    "        time.sleep(random.uniform(1, 2))  # respectful scraping\n",
    "\n",
    "    # Remove duplicates\n",
    "    urls = list(dict.fromkeys(urls))\n",
    "    print(f\"[INFO] Found {len(urls)} restaurant URLs.\")\n",
    "    return urls\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "668f3ff4-073e-4429-8ecb-d3b4d90ce630",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_review_block(block) -> Dict:\n",
    "    \"\"\"\n",
    "    Extract text, rating, date from a single Yelp review HTML block.\n",
    "    \"\"\"\n",
    "    # Review text\n",
    "    try:\n",
    "        text = block.select_one(\"span.raw__09f24__T4Ezm\").get_text(strip=True)\n",
    "    except:\n",
    "        text = \"\"\n",
    "\n",
    "    # Star rating\n",
    "    try:\n",
    "        rating_tag = block.select_one(\"div.i-stars__09f24__M1AR7\")\n",
    "        rating = float(rating_tag[\"aria-label\"].split()[0])\n",
    "    except:\n",
    "        rating = None\n",
    "\n",
    "    # Review date\n",
    "    try:\n",
    "        date = block.select_one(\"span.css-1e4fdj9\").get_text(strip=True)\n",
    "    except:\n",
    "        date = None\n",
    "\n",
    "    return {\n",
    "        \"review_text\": text,\n",
    "        \"review_rating\": rating,\n",
    "        \"review_date\": date\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "1dcb14b2-e8d3-4d53-be8a-00d28f794083",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_restaurant_reviews(url: str, max_pages=20) -> List[Dict]:\n",
    "    \"\"\"\n",
    "    Scrape *all* review pages for one restaurant.\n",
    "    \"\"\"\n",
    "    print(f\"[SCRAPE] {url}\")\n",
    "\n",
    "    reviews = []\n",
    "\n",
    "    for p in range(max_pages):\n",
    "        paged_url = f\"{url}?start={p * 10}\"\n",
    "\n",
    "        res = requests.get(paged_url, headers=HEADERS)\n",
    "        soup = BeautifulSoup(res.text, \"html.parser\")\n",
    "\n",
    "        # review containers\n",
    "        review_blocks = soup.select(\"div.review__09f24__oHr9V\")\n",
    "\n",
    "        if not review_blocks:\n",
    "            # no more review pages\n",
    "            break\n",
    "\n",
    "        for block in review_blocks:\n",
    "            rev = parse_review_block(block)\n",
    "            rev[\"restaurant_url\"] = url\n",
    "            reviews.append(rev)\n",
    "\n",
    "        time.sleep(random.uniform(1.0, 2.0))\n",
    "\n",
    "    print(f\"[DONE] {len(reviews)} reviews scraped.\")\n",
    "    return reviews\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "32ebda25-e185-4621-a0a6-cdd10f85f428",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_berlin_reviews(term=\"restaurants\", pages=3, max_review_pages=20):\n",
    "    \"\"\"\n",
    "    Scrape Yelp for Berlin restaurants and collect all their reviews.\n",
    "    Saves a CSV in data/raw.\n",
    "    \"\"\"\n",
    "    urls = search_yelp_berlin(term=term, pages=pages)\n",
    "    all_reviews = []\n",
    "\n",
    "    for url in urls:\n",
    "        try:\n",
    "            restaurant_reviews = scrape_restaurant_reviews(url, max_pages=max_review_pages)\n",
    "            all_reviews.extend(restaurant_reviews)\n",
    "        except Exception as e:\n",
    "            print(f\"[ERROR] Failed scraping {url}: {e}\")\n",
    "            continue\n",
    "\n",
    "    df = pd.DataFrame(all_reviews)\n",
    "    df[\"crawled_at\"] = datetime.utcnow().isoformat()\n",
    "\n",
    "    # Save raw dataset\n",
    "    df.to_csv(\"../data/raw/yelp_berlin_reviews_raw.csv\", index=False)\n",
    "    print(\"[SAVE] Saved to ../data/raw/yelp_berlin_reviews_raw.csv\")\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "503ae5da-c39b-4c1e-87f8-63e763d08520",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Fetching search page 1/3...\n",
      "[INFO] Fetching search page 2/3...\n",
      "[INFO] Fetching search page 3/3...\n",
      "[INFO] Found 0 restaurant URLs.\n",
      "[SAVE] Saved to ../data/raw/yelp_berlin_reviews_raw.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>crawled_at</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [crawled_at]\n",
       "Index: []"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = collect_berlin_reviews(\n",
    "    term=\"restaurants\", \n",
    "    pages=3,            # 3 search pages â†’ ~30 restaurants\n",
    "    max_review_pages=15 # scrape up to 150 reviews per restaurant\n",
    ")\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "389f8aa8-15cb-4bad-b0e4-7580f0dd626a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Status code: 403\n",
      "HTML length: 834\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "url = \"https://www.yelp.com/search?find_desc=restaurants&find_loc=Berlin%2C+Germany\"\n",
    "res = requests.get(url, headers=HEADERS)\n",
    "print(\"Status code:\", res.status_code)\n",
    "print(\"HTML length:\", len(res.text))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "f7ab2bcf-75ea-41ad-b374-bce497582b7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "US_PROXIES = [\n",
    "    \"http://104.248.63.17:30588\",\n",
    "    \"http://67.213.212.47:52215\",\n",
    "    \"http://38.153.137.2:999\",\n",
    "    \"http://154.236.168.179:1976\",\n",
    "    \"http://44.226.167.102:3128\",\n",
    "    \"http://50.18.33.231:8080\",\n",
    "    \"http://20.110.168.104:80\"\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "36d3f05d-01d8-4622-bbc4-1c92458d4996",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_random_proxy():\n",
    "    proxy = random.choice(US_PROXIES)\n",
    "    return {\n",
    "        \"http\": proxy,\n",
    "        \"https\": proxy\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "d0ae5eaa-b800-4131-bebf-46cde918127d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [403]>"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "requests.get(url, headers=HEADERS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "9b4ca86d-28ca-4af3-bbcc-2f32f0470c72",
   "metadata": {},
   "outputs": [
    {
     "ename": "ReadTimeout",
     "evalue": "HTTPSConnectionPool(host='www.yelp.com', port=443): Read timed out. (read timeout=10)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTimeoutError\u001b[0m                              Traceback (most recent call last)",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/berlin_bites/lib/python3.10/site-packages/urllib3/connectionpool.py:773\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[0m\n\u001b[1;32m    772\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 773\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_prepare_proxy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    774\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (BaseSSLError, \u001b[38;5;167;01mOSError\u001b[39;00m, SocketTimeout) \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/berlin_bites/lib/python3.10/site-packages/urllib3/connectionpool.py:1042\u001b[0m, in \u001b[0;36mHTTPSConnectionPool._prepare_proxy\u001b[0;34m(self, conn)\u001b[0m\n\u001b[1;32m   1036\u001b[0m conn\u001b[38;5;241m.\u001b[39mset_tunnel(\n\u001b[1;32m   1037\u001b[0m     scheme\u001b[38;5;241m=\u001b[39mtunnel_scheme,\n\u001b[1;32m   1038\u001b[0m     host\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tunnel_host,\n\u001b[1;32m   1039\u001b[0m     port\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mport,\n\u001b[1;32m   1040\u001b[0m     headers\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mproxy_headers,\n\u001b[1;32m   1041\u001b[0m )\n\u001b[0;32m-> 1042\u001b[0m \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/berlin_bites/lib/python3.10/site-packages/urllib3/connection.py:770\u001b[0m, in \u001b[0;36mHTTPSConnection.connect\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    768\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_has_connected_to_proxy \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m--> 770\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_tunnel\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    771\u001b[0m \u001b[38;5;66;03m# Override the host with the one we're requesting data from.\u001b[39;00m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/berlin_bites/lib/python3.10/site-packages/urllib3/connection.py:265\u001b[0m, in \u001b[0;36mHTTPConnection._tunnel\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    264\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 265\u001b[0m     (version, code, message) \u001b[38;5;241m=\u001b[39m \u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_read_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[1;32m    267\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m code \u001b[38;5;241m!=\u001b[39m http\u001b[38;5;241m.\u001b[39mHTTPStatus\u001b[38;5;241m.\u001b[39mOK:\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/lib/python3.10/http/client.py:279\u001b[0m, in \u001b[0;36mHTTPResponse._read_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    278\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_read_status\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m--> 279\u001b[0m     line \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreadline\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_MAXLINE\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124miso-8859-1\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    280\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(line) \u001b[38;5;241m>\u001b[39m _MAXLINE:\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/lib/python3.10/socket.py:705\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    704\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 705\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecv_into\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    706\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n",
      "\u001b[0;31mTimeoutError\u001b[0m: timed out",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mReadTimeoutError\u001b[0m                          Traceback (most recent call last)",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/berlin_bites/lib/python3.10/site-packages/requests/adapters.py:644\u001b[0m, in \u001b[0;36mHTTPAdapter.send\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    643\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 644\u001b[0m     resp \u001b[38;5;241m=\u001b[39m \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    645\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    646\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    647\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    648\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    649\u001b[0m \u001b[43m        \u001b[49m\u001b[43mredirect\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    650\u001b[0m \u001b[43m        \u001b[49m\u001b[43massert_same_host\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    651\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    652\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    653\u001b[0m \u001b[43m        \u001b[49m\u001b[43mretries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    654\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    655\u001b[0m \u001b[43m        \u001b[49m\u001b[43mchunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    656\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    658\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (ProtocolError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/berlin_bites/lib/python3.10/site-packages/urllib3/connectionpool.py:841\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[0m\n\u001b[1;32m    839\u001b[0m     new_e \u001b[38;5;241m=\u001b[39m ProtocolError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConnection aborted.\u001b[39m\u001b[38;5;124m\"\u001b[39m, new_e)\n\u001b[0;32m--> 841\u001b[0m retries \u001b[38;5;241m=\u001b[39m \u001b[43mretries\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mincrement\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    842\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merror\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnew_e\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_pool\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_stacktrace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msys\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexc_info\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[1;32m    843\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    844\u001b[0m retries\u001b[38;5;241m.\u001b[39msleep()\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/berlin_bites/lib/python3.10/site-packages/urllib3/util/retry.py:474\u001b[0m, in \u001b[0;36mRetry.increment\u001b[0;34m(self, method, url, response, error, _pool, _stacktrace)\u001b[0m\n\u001b[1;32m    473\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m read \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m method \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_is_method_retryable(method):\n\u001b[0;32m--> 474\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[43mreraise\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mtype\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43merror\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merror\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_stacktrace\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    475\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m read \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/berlin_bites/lib/python3.10/site-packages/urllib3/util/util.py:39\u001b[0m, in \u001b[0;36mreraise\u001b[0;34m(tp, value, tb)\u001b[0m\n\u001b[1;32m     38\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m value\u001b[38;5;241m.\u001b[39mwith_traceback(tb)\n\u001b[0;32m---> 39\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m value\n\u001b[1;32m     40\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/berlin_bites/lib/python3.10/site-packages/urllib3/connectionpool.py:775\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[0m\n\u001b[1;32m    774\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (BaseSSLError, \u001b[38;5;167;01mOSError\u001b[39;00m, SocketTimeout) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m--> 775\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_raise_timeout\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    776\u001b[0m \u001b[43m        \u001b[49m\u001b[43merr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43me\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mproxy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtimeout\u001b[49m\n\u001b[1;32m    777\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    778\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/berlin_bites/lib/python3.10/site-packages/urllib3/connectionpool.py:367\u001b[0m, in \u001b[0;36mHTTPConnectionPool._raise_timeout\u001b[0;34m(self, err, url, timeout_value)\u001b[0m\n\u001b[1;32m    366\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(err, SocketTimeout):\n\u001b[0;32m--> 367\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m ReadTimeoutError(\n\u001b[1;32m    368\u001b[0m         \u001b[38;5;28mself\u001b[39m, url, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRead timed out. (read timeout=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtimeout_value\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    369\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m    371\u001b[0m \u001b[38;5;66;03m# See the above comment about EAGAIN in Python 3.\u001b[39;00m\n",
      "\u001b[0;31mReadTimeoutError\u001b[0m: HTTPSConnectionPool(host='www.yelp.com', port=443): Read timed out. (read timeout=10)",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mReadTimeout\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[52], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mrequests\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mHEADERS\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mproxies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mget_random_proxy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/berlin_bites/lib/python3.10/site-packages/requests/api.py:73\u001b[0m, in \u001b[0;36mget\u001b[0;34m(url, params, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mget\u001b[39m(url, params\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m     63\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Sends a GET request.\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \n\u001b[1;32m     65\u001b[0m \u001b[38;5;124;03m    :param url: URL for the new :class:`Request` object.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[38;5;124;03m    :rtype: requests.Response\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 73\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mget\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/berlin_bites/lib/python3.10/site-packages/requests/api.py:59\u001b[0m, in \u001b[0;36mrequest\u001b[0;34m(method, url, **kwargs)\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;66;03m# By using the 'with' statement we are sure the session is closed, thus we\u001b[39;00m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;66;03m# avoid leaving sockets open which can trigger a ResourceWarning in some\u001b[39;00m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;66;03m# cases, and look like a memory leak in others.\u001b[39;00m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m sessions\u001b[38;5;241m.\u001b[39mSession() \u001b[38;5;28;01mas\u001b[39;00m session:\n\u001b[0;32m---> 59\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43msession\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/berlin_bites/lib/python3.10/site-packages/requests/sessions.py:589\u001b[0m, in \u001b[0;36mSession.request\u001b[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[1;32m    584\u001b[0m send_kwargs \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    585\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtimeout\u001b[39m\u001b[38;5;124m\"\u001b[39m: timeout,\n\u001b[1;32m    586\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mallow_redirects\u001b[39m\u001b[38;5;124m\"\u001b[39m: allow_redirects,\n\u001b[1;32m    587\u001b[0m }\n\u001b[1;32m    588\u001b[0m send_kwargs\u001b[38;5;241m.\u001b[39mupdate(settings)\n\u001b[0;32m--> 589\u001b[0m resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprep\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43msend_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    591\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m resp\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/berlin_bites/lib/python3.10/site-packages/requests/sessions.py:703\u001b[0m, in \u001b[0;36mSession.send\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    700\u001b[0m start \u001b[38;5;241m=\u001b[39m preferred_clock()\n\u001b[1;32m    702\u001b[0m \u001b[38;5;66;03m# Send the request\u001b[39;00m\n\u001b[0;32m--> 703\u001b[0m r \u001b[38;5;241m=\u001b[39m \u001b[43madapter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    705\u001b[0m \u001b[38;5;66;03m# Total elapsed time of the request (approximately)\u001b[39;00m\n\u001b[1;32m    706\u001b[0m elapsed \u001b[38;5;241m=\u001b[39m preferred_clock() \u001b[38;5;241m-\u001b[39m start\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/berlin_bites/lib/python3.10/site-packages/requests/adapters.py:690\u001b[0m, in \u001b[0;36mHTTPAdapter.send\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    688\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m SSLError(e, request\u001b[38;5;241m=\u001b[39mrequest)\n\u001b[1;32m    689\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(e, ReadTimeoutError):\n\u001b[0;32m--> 690\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m ReadTimeout(e, request\u001b[38;5;241m=\u001b[39mrequest)\n\u001b[1;32m    691\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(e, _InvalidHeader):\n\u001b[1;32m    692\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m InvalidHeader(e, request\u001b[38;5;241m=\u001b[39mrequest)\n",
      "\u001b[0;31mReadTimeout\u001b[0m: HTTPSConnectionPool(host='www.yelp.com', port=443): Read timed out. (read timeout=10)"
     ]
    }
   ],
   "source": [
    "requests.get(url, headers=HEADERS, proxies=get_random_proxy(), timeout=10)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "719e56d7-f580-46ef-9958-9f6443b2b16c",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'base_url' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[53], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m res \u001b[38;5;241m=\u001b[39m requests\u001b[38;5;241m.\u001b[39mget(\u001b[43mbase_url\u001b[49m, headers\u001b[38;5;241m=\u001b[39mHEADERS, params\u001b[38;5;241m=\u001b[39mparams)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'base_url' is not defined"
     ]
    }
   ],
   "source": [
    "res = requests.get(base_url, headers=HEADERS, params=params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d37100a1-f8b3-493c-9296-af81c5ba238f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
